<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>WebLLM Phi-mini Demo (CDN)</title>
  <style>
    body { font-family: Inter, system-ui, sans-serif; background:#0b1220; color:#e6eef6; padding:28px; }
    .card { max-width:880px; margin:0 auto; padding:22px; border-radius:12px; background:linear-gradient(180deg,#071028,#071424); box-shadow:0 8px 30px rgba(0,0,0,0.6); }
    textarea { width:100%; min-height:140px; padding:12px; border-radius:8px; border:1px solid rgba(255,255,255,0.04); background:rgba(255,255,255,0.02); color:inherit; }
    button { background:#7c3aed; border:none; color:white; padding:10px 14px; border-radius:10px; cursor:pointer; }
    #output { white-space:pre-wrap; margin-top:12px; padding:12px; border-radius:8px; background:rgba(255,255,255,0.01); min-height:140px; border:1px solid rgba(255,255,255,0.02); }
    .muted { color:#9aa4b2; font-size:13px; }
  </style>
</head>
<body>
  <div class="card">
    <h2>WebLLM Demo (CDN Model)</h2>
    <p class="muted">Uses a free, open-source model hosted on a CDN. Runs fully in browser with WebGPU.</p>
    <textarea id="prompt">Write a short paragraph about the benefits of indoor plants.</textarea>
    <div style="margin-top:10px; display:flex; gap:8px; align-items:center;">
      <button id="generateBtn">Generate</button>
      <button id="clearBtn" style="background:#2b3148">Clear</button>
      <div style="flex:1"></div>
      <div id="status" class="muted">Status: idle</div>
    </div>
    <div id="output">— output appears here —</div>
  </div>

<script type="module">
import * as webllm from "https://esm.run/@mlc-ai/web-llm";

const status = (t) => { document.getElementById('status').innerText = 'Status: ' + t; };

let engine = null;
let modelReady = false;

// CDN-hosted open-source Phi-mini model
const MODEL_CDN = "https://huggingface.co/llm-foundation/phi-1_5-mini/resolve/main/"; // example, free model CDN

async function initEngine() {
  if (engine) return engine;
  status('Initializing WebLLM engine…');
  engine = await webllm.CreateWebWorkerMLCEngine({
    model: MODEL_CDN,
    device: 'webgpu',
    num_worker_threads: 1
  });
  status('Engine ready — loading model...');
  modelReady = true;
  status('Model loaded ✔ Ready');
  return engine;
}

async function generate(prompt) {
  if (!prompt) return;
  document.getElementById('output').innerText = 'Thinking…';
  try {
    await initEngine();
    status('Generating…');
    const response = await engine.chat.completions.create({
      model: MODEL_CDN,
      messages: [{ role: "user", content: prompt }],
      max_tokens: 200,
      temperature: 0.7
    });
    const text = response?.choices?.[0]?.message?.content || 'No output';
    document.getElementById('output').innerText = text;
    status('Done ✔');
  } catch(err) {
    console.error(err);
    document.getElementById('output').innerText = 'Generation error: ' + (err?.message || err);
    status('Error — see console');
  }
}

document.getElementById('generateBtn').addEventListener('click', async () => {
  const p = document.getElementById('prompt').value.trim();
  await generate(p);
});
document.getElementById('clearBtn').addEventListener('click', () => {
  document.getElementById('output').innerText = '— output appears here —';
});
</script>
</body>
</html>
